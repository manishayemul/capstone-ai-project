# ğŸ¤– Agentic AI System â€“ Ciklum AI Academy Capstone

This project implements a self-reflective Agentic AI system built using Node.js and a locally hosted LLM (Ollama).

The system demonstrates Retrieval-Augmented Generation (RAG), tool-based reasoning, reflection, and evaluation within a cohesive autonomous workflow.

---

## ğŸ¯ Objective

The goal of this project is to design and implement an AI agent capable of:

- Retrieving contextual data (RAG)
- Performing autonomous reasoning
- Executing tool-based actions
- Reflecting on its own output
- Evaluating response quality

This project was created as part of the **Ciklum AI Academy**.

---

## ğŸ— Architecture Overview

The agent follows this workflow:

User Query  
â†’ Context Retrieval (RAG)  
â†’ LLM Generation  
â†’ Reflection Step  
â†’ Evaluation Step  
â†’ Final Improved Output  

See `architecture.mmd` for a visual diagram.

---

## ğŸ§  Key Features

- âœ… Local LLM using Ollama (no paid APIs)
- âœ… Context retrieval from project files
- âœ… Tool-based LinkedIn post generation
- âœ… Self-reflection and improvement
- âœ… Structured evaluation scoring

---

## ğŸ›  Tech Stack

- Node.js
- TypeScript
- Ollama (Llama 3 model)
- Mermaid (architecture diagram)

---

## ğŸš€ How to Run

### 1ï¸âƒ£ Install Ollama

Download and install:

https://ollama.com/download

Pull the model:

```bash
ollama pull llama3
