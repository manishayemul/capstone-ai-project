# ğŸ¤– Agentic AI System â€“ Ciklum AI Academy Capstone

This project implements a self-reflective **Agentic AI system** built using **Node.js** and a locally hosted **LLM (Ollama)**.

The system demonstrates **Retrieval-Augmented Generation (RAG)**, tool-based reasoning, reflection, and evaluation within a cohesive autonomous workflow.

---

## ğŸ¯ Objective

The goal of this project is to design and implement an AI agent capable of:

* Retrieving contextual data (RAG)
* Performing autonomous reasoning
* Executing tool-based actions
* Reflecting on its own output
* Evaluating response quality

This project was created as part of the **Ciklum AI Academy**.

---

## ğŸ— Architecture Overview

The agent follows this workflow:

```
User Query
â†’ Context Retrieval (RAG)
â†’ LLM Generation
â†’ Reflection Step
â†’ Evaluation Step
â†’ Final Improved Output
```

See `architecture.mmd` for the visual diagram.

---

## ğŸ§  Key Features

* âœ… Local LLM using Ollama (no paid APIs)
* âœ… Context retrieval from project files
* âœ… Tool-based LinkedIn post generation
* âœ… Self-reflection and improvement
* âœ… Structured evaluation scoring

---

## ğŸ›  Tech Stack

* Node.js
* TypeScript
* Ollama (Llama 3)
* Mermaid (architecture diagram)

---

## ğŸ“ Project Structure

```
src/
 â”œâ”€â”€ agent.ts        # Workflow orchestration
 â”œâ”€â”€ rag.ts          # Context retrieval
 â”œâ”€â”€ tools.ts        # Content generation
 â”œâ”€â”€ reflection.ts   # Self-reflection logic
 â”œâ”€â”€ evaluation.ts   # Output evaluation
 â””â”€â”€ main.ts         # Entry point
```

---

## ğŸš€ How to Run

### 1ï¸âƒ£ Install Ollama

Download and install from:

[https://ollama.com/download](https://ollama.com/download)

Verify installation:

```bash
ollama --version
```

---

### 2ï¸âƒ£ Pull the Model

```bash
ollama pull llama3
```

---

### 3ï¸âƒ£ Install Dependencies

Inside the project folder:

```bash
npm install
```

---

### 4ï¸âƒ£ Run the Agent

```bash
npx tsx src/main.ts
```

---

## âœ… Requirements

* Node.js v18+
* Ollama installed and running
* `llama3` model pulled locally

---

## ğŸ¥ Demo

A demo video showcases:

* Architecture explanation
* Code structure walkthrough
* Live execution
* Final evaluated output

---

## ğŸ’¡ Why This Is Agentic

Unlike a traditional chatbot, this system:

* Retrieves contextual knowledge
* Generates structured output
* Reflects and improves its response
* Evaluates quality before final delivery

This demonstrates autonomous reasoning and self-correction.
